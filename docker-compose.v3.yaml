# v3: Kafka with Flink for stream processing
# Usage: docker compose -f docker-compose.base.yaml -f docker-compose.v3.yaml up -d

services:
  kafka:
    container_name: kafka
    image: apache/kafka:4.1.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 0
      KAFKA_PROCESS_ROLES: controller,broker
      KAFKA_CONTROLLER_QUORUM_VOTERS: 0@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - coffee-rt

  kafka-init:
    container_name: kafka-init
    image: apache/kafka:4.1.1
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    volumes:
      - ./.dev/kafka-init/init.sh:/init.sh:ro
    entrypoint: ["/bin/bash", "/init.sh"]
    networks:
      - coffee-rt

  cafe-order-api:
    container_name: cafe-order-api
    build:
      context: .
      dockerfile: backend/cafe_order_api/Dockerfile
    ports:
      - "8005:8005"
    depends_on:
      db-migrate:
        condition: service_completed_successfully
      redis-init:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_USER: coffee-rt
      POSTGRES_PASSWORD: coffee-rt_password
      POSTGRES_DB: coffee-rt
      POSTGRES_SCHEMA: coffee_rt
      REDIS_HOST: redis
      REDIS_PORT: 6379
      LOG_FILE: /var/log/apps/api.log
      DASHBOARD_UPDATE_INTERVAL: 10
      CONNECTION_MAX_RETRIES: 10
      CONNECTION_INITIAL_BACKOFF: 2.0
      DB_POOL_MIN_SIZE: 5
      DB_POOL_MAX_SIZE: 20
      KAFKA_ENABLED: "true"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    volumes:
      - ./logs:/var/log/apps
    networks:
      - coffee-rt

  flink-jobmanager:
    container_name: flink-jobmanager
    image: flink:1.18-java11
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.memory.process.size: 1024m
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
    volumes:
      - flink_checkpoints:/opt/flink/checkpoints
      - flink_savepoints:/opt/flink/savepoints
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/overview || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - coffee-rt

  flink-taskmanager:
    container_name: flink-taskmanager
    image: flink:1.18-java11
    command: taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        taskmanager.memory.process.size: 1536m
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
    volumes:
      - flink_checkpoints:/opt/flink/checkpoints
      - flink_savepoints:/opt/flink/savepoints
    networks:
      - coffee-rt

  flink-job:
    container_name: flink-job
    build:
      context: ./flink/coffee-rt-flink
      dockerfile: Dockerfile
    depends_on:
      flink-taskmanager:
        condition: service_started
      db-migrate:
        condition: service_completed_successfully
      kafka-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: orders
      KAFKA_CONSUMER_GROUP: flink-processors
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: coffee-rt
      POSTGRES_USER: coffee-rt
      POSTGRES_PASSWORD: coffee-rt_password
      POSTGRES_SCHEMA: coffee_rt
      REDIS_HOST: redis
      REDIS_PORT: 6379
      WINDOW_SECONDS: 1
      CHECKPOINTING_ENABLED: "true"
      CHECKPOINT_INTERVAL_MS: "10000"
      CHECKPOINT_TIMEOUT_MS: "60000"
      MIN_PAUSE_BETWEEN_CHECKPOINTS_MS: "1000"
      MAX_CONCURRENT_CHECKPOINTS: "1"
      CHECKPOINT_DIR: "file:///opt/flink/checkpoints"
    volumes:
      - flink_checkpoints:/opt/flink/checkpoints
    entrypoint: >
      /bin/sh -c "
        sleep 10 &&
        flink run -m flink-jobmanager:8081 /opt/flink/usrlib/coffee-rt-flink.jar
      "
    networks:
      - coffee-rt
    restart: on-failure

volumes:
  kafka_data:
  flink_checkpoints:
  flink_savepoints:
