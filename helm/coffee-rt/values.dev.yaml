# Development values for Coffee RT
# Usage: helm install coffee-rt ./helm/coffee-rt -f ./helm/coffee-rt/values.dev.yaml
#
# For local development with locally built images, use imagePullPolicy: Never
# Build images locally first:
#   docker build -t coffee-rt/cafe-order-api:latest -f backend/cafe_order_api/Dockerfile .
#   docker build -t coffee-rt/cafe-order-aggregator:latest -f backend/cafe_order_aggregator/Dockerfile.cron .
#   docker build -t coffee-rt/stream-worker:latest -f backend/stream_worker/Dockerfile .
#   docker build -t coffee-rt/cafe-dashboard:latest ./frontend

# Global configuration
global:
  imageRegistry: ""
  imagePullSecrets: []

# Enable all services
api:
  enabled: true
  replicaCount: 4
  image:
    repository: coffee-rt/cafe-order-api
    tag: latest
    pullPolicy: Never  # Use local images
  service:
    type: ClusterIP
    port: 8005
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi


  dashboardUpdateInterval: 10


aggregator:
  enabled: true
  schedule: "* * * * *"  # Every minute
  image:
    repository: coffee-rt/cafe-order-aggregator
    tag: latest
    pullPolicy: Never  # Use local images
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 64Mi

stream-worker:
  enabled: true
  replicaCount: 1
  image:
    repository: coffee-rt/stream-worker
    tag: latest
    pullPolicy: Never
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 64Mi
  stream:
    name: orders:stream
    consumerGroup: order-workers

flink:
  enabled: true
  jobmanager:
    replicas: 1
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 512Mi
  taskmanager:
    replicas: 1
    taskSlots: 2
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 512Mi
  job:
    image:
      repository: coffee-rt/flink-job
      tag: latest
      pullPolicy: Never
    kafka:
      topic: orders
      consumerGroup: flink-processors

frontend:
  enabled: true
  image:
    repository: coffee-rt/cafe-dashboard
    tag: latest
    pullPolicy: Never  # Use local images
  service:
    type: ClusterIP
    port: 80
  resources:
    limits:
      cpu: 200m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

# Database configuration for secret creation
database:
  password: coffee-rt_password

# PostgreSQL subchart configuration (Bitnami)
postgresql:
  enabled: true
  image:
    tag: latest
    pullPolicy: IfNotPresent
  auth:
    username: coffee-rt
    password: coffee-rt_password
    database: coffee-rt
  primary:
    initdb:
      scripts:
        init-schema.sql: |
          CREATE SCHEMA IF NOT EXISTS coffee_rt;

          DO $$ BEGIN
              CREATE TYPE coffee_rt.drink AS ENUM ('cappuccino', 'americano', 'latte');
          EXCEPTION
              WHEN duplicate_object THEN null;
          END $$;

          DO $$ BEGIN
              CREATE TYPE coffee_rt.store AS ENUM ('uptown', 'downtown', 'central', 'southend');
          EXCEPTION
              WHEN duplicate_object THEN null;
          END $$;

          CREATE TABLE IF NOT EXISTS coffee_rt.orders (
              id SERIAL PRIMARY KEY,
              message_id VARCHAR(36) UNIQUE,
              drink coffee_rt.drink NOT NULL,
              store coffee_rt.store NOT NULL,
              price NUMERIC(10, 2) NOT NULL,
              timestamp TIMESTAMP NOT NULL DEFAULT NOW()
          );

          -- Add message_id column if table exists without it (migration)
          DO $$
          BEGIN
              IF NOT EXISTS (
                  SELECT 1 FROM information_schema.columns
                  WHERE table_schema = 'coffee_rt'
                  AND table_name = 'orders'
                  AND column_name = 'message_id'
              ) THEN
                  ALTER TABLE coffee_rt.orders ADD COLUMN message_id VARCHAR(36) UNIQUE;
              END IF;
          END $$;
    persistence:
      enabled: true
      size: 1Gi

# Redis subchart configuration (Bitnami)
redis:
  enabled: true
  architecture: standalone
  auth:
    enabled: false
  image:
    tag: latest
    pullPolicy: IfNotPresent
  master:
    persistence:
      enabled: true
      size: 1Gi

# Kafka subchart configuration (Bitnami) - KRaft mode (no Zookeeper)
kafka:
  enabled: true
  listeners:
    client:
      protocol: PLAINTEXT
    controller:
      protocol: PLAINTEXT
    interbroker:
      protocol: PLAINTEXT
  controller:
    replicaCount: 1
  kraft:
    enabled: true
  persistence:
    enabled: true
    size: 2Gi

# Prometheus configuration
prometheus:
  enabled: true
  server:
    persistentVolume:
      enabled: false
    service:
      type: ClusterIP
  # Extra scrape configs for our app and kube-state-metrics
  extraScrapeConfigs: |
    - job_name: 'coffee-rt-api'
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
              - coffee-ns
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
    - job_name: 'kube-state-metrics'
      static_configs:
        - targets: ['coffee-rt-kube-state-metrics:8080']

# Loki configuration (log aggregation)
loki:
  enabled: true
  deploymentMode: SingleBinary
  loki:
    auth_enabled: false
    commonConfig:
      replication_factor: 1
    storage:
      type: filesystem
    rulerConfig:
      storage:
        type: local
  singleBinary:
    replicas: 1
    persistence:
      enabled: false
    extraVolumes:
      - name: data
        emptyDir: {}
    extraVolumeMounts:
      - name: data
        mountPath: /var/loki
  read:
    replicas: 0
  write:
    replicas: 0
  backend:
    replicas: 0
  gateway:
    enabled: false
  test:
    enabled: false
  lokiCanary:
    enabled: false
  chunksCache:
    enabled: false
  resultsCache:
    enabled: false

# Promtail configuration (log collector)
promtail:
  enabled: true
  config:
    clients:
      - url: http://coffee-rt-loki:3100/loki/api/v1/push

# Grafana configuration
grafana:
  enabled: true
  adminUser: admin
  adminPassword: admin
  service:
    type: ClusterIP
    port: 80
  persistence:
    enabled: false
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://coffee-rt-prometheus-server:80
          access: proxy
          isDefault: true
        - name: Loki
          type: loki
          url: http://coffee-rt-loki:3100
          access: proxy
          jsonData:
            maxLines: 1000
